import cv2
import mediapipe as mp
import joblib
import numpy as np

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = joblib.load("sign_knn_model_v1.pkl")

# Mediapipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)

# í…ŒìŠ¤íŠ¸í•  ì˜ìƒ ê²½ë¡œ
video_path = "videos/ë§ˆìŒì˜ì•½ì†.mp4"
cap = cv2.VideoCapture(video_path)

coords_list = []

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break

    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    if result.multi_hand_landmarks:
        for hand in result.multi_hand_landmarks:
            coords = []
            for lm in hand.landmark:
                coords += [lm.x, lm.y, lm.z]
            if len(coords) == 63:
                coords_list.append(coords)

cap.release()

# ì˜ˆì¸¡
if coords_list:
    avg_coords = np.mean(coords_list, axis=0).reshape(1, -1)

    # KNN ê±°ë¦¬ í™•ì¸
    distances, _ = model.kneighbors(avg_coords)
    avg_distance = np.mean(distances)
    print(f"ğŸ“ í‰ê·  ê±°ë¦¬: {avg_distance:.4f}")

    # ì„ê³„ê°’ ë¹„êµ
    if avg_distance > 0.15:
        print("ğŸ¤– ì¸ì‹ ê²°ê³¼: ì•Œ ìˆ˜ ì—†ìŒ (ë‚¯ì„  ìˆ˜ì–´)")
    else:
        pred = model.predict(avg_coords)
        print(f"ğŸ¤– ì¸ì‹ ê²°ê³¼: {pred[0]}")
else:
    print("âš ï¸ ì† ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì¢Œí‘œ ì—†ìŒ")


#     pred = model.predict(avg_coords)
#     print(f"[ğŸ¤– ì˜ˆì¸¡ ê²°ê³¼] ì´ ìˆ˜ì–´ëŠ” â†’ {pred[0]}")
# else:
#     print("âš ï¸ ì† ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì¢Œí‘œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
